---
title: "The Expanding Dark Forest and Generative AI"
description: "Proving you're a human on a web flooded with generative AI content"
updated: "2023-01-02"
startDate: "2022-12-31"
type: "note"
topics: ["Anthropology", "The Web", "Artificial Intelligence"]
growthStage: "budding"
---

<AssumedAudience>
  People who have heard of GPT-3 / ChatGPT, and are vaguely following the
  advances in machine learning, large language models, and image generators.
</AssumedAudience>

<Spacer size="xs" />

<IntroParagraph>

The [[dark forest theory]] of the web points to the increasingly like-like but life-less state of being online.<Footnote idName={1}>[Dark Forest](https://onezero.medium.com/the-dark-forest-theory-of-the-internet-7dc3e68a7cb1) [Theory of](https://onezero.medium.com/the-dark-forest-theory-of-the-internet-7dc3e68a7cb1) [the Internet](https://onezero.medium.com/the-dark-forest-theory-of-the-internet-7dc3e68a7cb1) by Yancey Strickler</Footnote> Most open and publicly available spaces on the web are overrun with bots, advertisers, trolls, data scrapers, clickbait, keyword-stuffing ‚Äúcontent creators,‚Äù and algorithmically manipulated junk.

</IntroParagraph>

It's like a dark forest that seems eerily devoid of human life ‚Äì all the living creatures are hidden beneath the ground or up in trees. If they reveal themselves, they risk being attacked by automated predators.

Humans who want to engage in informal, unoptimised, personal interactions have to hide in closed spaces like invite-only Slack channels, Discord groups, email newsletters, small-scale blogs, and [[digital gardens]]. Or make themselves [illegible](https://www.ribbonfarm.com/2010/07/26/a-big-little-idea-called-legibility/) and algorithmically incoherent in public venues.

<ResponsiveImage
  width="1000px"
  alt="An illustration of layers of the web: the dark forest on top, followed by layers of cozyweb holes where people hide away from bots and ad scavengers"
  src="/images/posts/ai-dark-forest/cozyweb.png"
/>

That dark forest is about to <div style={{transform: "scaleX(1.85)", display: "inline-flex", margin: "0 2.2rem"}}>expand</div>. Large Language Models (LLMs) that can instantly generate coherent swaths of human-like text have just joined the party.

Over the last six months, we've seen a flood of LLM copywriting and content-generation products come out: [Jasper](https://www.jasper.ai/), [Moonbeam](https://www.gomoonbeam.com/), [Copy.ai](https://www.copy.ai/), and [Anyword](https://anyword.com/) are just a few. They're designed to pump out advertising copy, blog posts, emails, social media updates, and marketing pages. And they're _really_ good at it.<Footnote idName={2}>Primarily because [GPT-3](https://en.wikipedia.org/wiki/GPT-3) which powers many of these products was specifically trained on text from the web. It's intimately familiar with the style of language we use online.</Footnote>

These models became competent copywriters much faster than people expected ‚Äì too fast for us to fully process the implications. Many people had their come-to-Jesus moment a few weeks ago when OpenAI released [ChatGPT](https://openai.com/blog/chatgpt/), a slightly more capable version of GPT-3 with an accessible chat-bot style interface. <Footnote idName={3}>They're calling it GPT-3.5. It's the same model with human [reinforcement learning](https://huggingface.co/blog/rlhf) layered on top.</Footnote> The [collective](https://twitter.com/elonmusk/status/1599128577068650498?s=20&t=MgaSdgsaF0uU1lITCVPghw) [shock](https://twitter.com/volodarik/status/1600854935515844610?s=20&t=MgaSdgsaF0uU1lITCVPghw) and [awe](https://twitter.com/yu_angela/status/1599808692085743616?s=20&t=MgaSdgsaF0uU1lITCVPghw) [reaction](https://twitter.com/levie/status/1599156293050433536?s=20&t=MgaSdgsaF0uU1lITCVPghw) made clear how few people had been tracking the progress of these models.

To complicate matters, language models are not the only mimicry machines gathering speed right now. Image generators like [Midjourney](https://www.midjourney.com/home/?callbackUrl=/app/), [DALL-E](https://openai.com/dall-e-2/), and [Stable Diffusion](https://en.wikipedia.org/wiki/Stable_Diffusion) have been on a year-long sprint. In January they could barely render a low-resolution, disfigured human face. By the autumn they reliably produced images indistinguishable from the work of human photographers and illustrators.

<TwoColumn maxWidth="1100px">

<ResponsiveImage src="/images/posts/ai-dark-forest/mj8.png" alt="..." />

<ResponsiveImage src="/images/posts/ai-dark-forest/mj1.png" alt="..." />

<ResponsiveImage src="/images/posts/ai-dark-forest/mj7.png" alt="..." />

<ResponsiveImage src="/images/posts/ai-dark-forest/mj3.png" alt="..." />

<ResponsiveImage src="/images/posts/ai-dark-forest/mj9.png" alt="..." />

<ResponsiveImage src="/images/posts/ai-dark-forest/mj4.png" alt="..." />

</TwoColumn>

<Subtext>Images I generated with Midjourney's V4 model</Subtext>

## A Generated Web

There's a swirl of optimism around how these models will save us from a suite of boring busywork: writing formal emails, internal memos, technical documentation, marketing copy, product announcement, advertisements, cover letters, and even negotiating with medical [insurance companies](https://twitter.com/StuartBlitz/status/1602834224284897282).

But we'll also need to reckon with the trade-offs of making insta-paragraphs and 1-click cover images. These new models are poised to flood the web with generic, generated content.

You thought the first page of Google was bunk before? You haven't seen Google where SEO optimizer bros pump out billions of perfectly coherent but predictably dull informational articles for every longtail keyword combination under the sun.

Marketers, influencers, and growth hackers will set up [OpenAI ‚Üí Zapier](https://zapier.com/apps/openai/integrations) pipelines that auto-publish a relentless and impossibly banal stream of LinkedIn #MotivationMonday posts, ‚Äúengaging‚Äù tweet <span role="img">üßµ</span> threads, Facebook outrage monologues, and corporate blog posts.

It goes beyond text too: [video essays on YouTube](https://twitter.com/SamRo/status/1605919856808714240?s=20&t=QB-eYoISuymlqbHFFDnrWw), TikTok clips, podcasts, slide decks, and Instagram stories can all be generated by [patchworking](https://runwayml.com/) together ML systems. And then [regurgitated](https://byautomata.io/) for each medium.

We're about to drown in a sea of pedestrian takes. An explosion of noise that will drown out any signal. Goodbye to finding original human insights or authentic connections under that pile of cruft.

Many people will say we already live in this reality. We've already become skilled at sifting through unhelpful piles of ‚Äúoptimised content‚Äù designed to gather clicks and advertising impressions.

4chan proposed [dead internet theory](https://www.theatlantic.com/technology/archive/2021/08/dead-internet-theory-wrong-but-feels-true/619937/) years ago: that most of the internet is ‚Äúempty and devoid of people‚Äù and has been taken over by artificial intelligence. A milder version of this theory is simply that we're overrun [with bots](https://nymag.com/intelligencer/2018/12/how-much-of-the-internet-is-fake.html). Most of us take that for granted at this point.

But I think the sheer volume and scale of what's coming will be meaningfully different. And I think we're unprepared. Or at least, I am.

---

## Passing the Reverse Turing Test

Our new challenge as little snowflake humans will be to prove we aren't language models. It's the reverse [turing test](https://en.wikipedia.org/wiki/Turing_test).

<TweetEmbed tweetId="1601541418153304064" />

<TweetEmbed tweetId="1601750189974245377" />

After the forest expands, we will all become deeply skeptical. Every time you find a new favourite blog or twitter account or tiktok personality online, you'll have to ask: Is this really a whole human with a rich and complex life like mine? Is there a _being_ on the other end of this web interface I can form a relationship with?<Footnote idName={4}>‚ÄúRelationship‚Äù in the holistic sense ‚Äì friend, acquaintance, pen pal, intellectual interlocutor, frenemy, drinking buddy, and sure, maybe a lover.</Footnote>

Before you continue, pause and consider: How would _you_ prove you're not a language model generating predictive text? What special human tricks can you do that a language model can't?

### 1. Triangulate objective reality

As language models become increasingly capable and impressive, we should remember they are, at their core, simple linguistic [prediction systems](https://www.datacamp.com/blog/a-beginners-guide-to-gpt-3#:~:text=Language%20modeling%20is,predicting%20word%20sequences.). They cannot (yet) reason like a human.

They do not have beliefs based on evidence, claims, and principles. They cannot consult external sources and run experiments against objective reality. They cannot go outside and touch grass.

In short, they do not have access to the same shared reality we do. They do not have embodied experiences, and cannot sense the world as we can sense it; they don't have vision, sound, taste, or touch. They cannot feel emotion or tightly hold a coherent set of values. They are not part of cultures, communities, or histories.

They are a language model in a box. If a historical event, fact, person, or concept wasn't part of their training data, they can't tell you about it. They don't know about events that happened after a certain cutoff date. <Footnote idName={5}>Currently 2021 for GPT-3 / ChatGPT, but we can expect that to regularly update as new models are trained</Footnote>

This leaves us with some low-hanging fruit for humanness. We can tell richly detailed stories grounded in our specific contexts and cultures: place names, sensual descriptions, local knowledge, and, well the _je ne sais quoi_ of being alive. Language models can decently mimic this style of writing but most don't without extensive prompt engineering. They stick to generics. They hedge. They leave out details. They have trouble maintaining a coherent sense of self over thousands of words.

Hipsterism and recency bias will help us here. Referencing obscure concepts, friends who are real but not famous, niche interests, and recent events all make you plausibly more human.<Footnote idName={6}>This feels eerily like a hostage holding up yesterday's newspaper to prove they are actively in danger. Perhaps a premonition.</Footnote>

### 2. Be original, critical, and sophisticated

Easier said than done, but one of the best ways to prove you're not a predictive language model is to demonstrate critical and sophisticated thinking.

Language models spit out text that sounds like a B+ college essay. Coherent, seemingly comprehensive, but never truly insightful or original.

In a repulsively evocative metaphor, they engage in ‚Äú[human centipede](<https://en.wikipedia.org/wiki/The_Human_Centipede_(First_Sequence)>) epistemology.‚Äù<Footnote idName={7}>I found this phrase via Twitter, but posted from a private account so I won't cite the original author.</Footnote> Language models regurgitate text from across the web, which some humans read and recycle into "original creations," which then become fodder to train other language models, and around and around we go recycling generic ideas and arguments and tropes and ways of thinking.

Hard exiting out of this cycle requires coming up with unquestionably original thoughts and theories. It means seeing and synthesising patterns across a broad range of sources: books, blogs, cultural narratives served up by media outlets, conversations, podcasts, lived experiences, and market trends. We can observe and analyse a much fuller range of inputs than bots and generative models can.

It will raise the stakes for everyone. As both consumers of content and creators of it, we'll have to foster a greater sense of critical thinking and scepticism.

This all sounds a bit rough, but there's a lot of hope in this vision. In a world of automated intelligence, our goalposts for intelligence will shift. We'll raise our quality bar for what we expect from humans. When a machine can pump out a great literature review or summary of existing work, there's no value in a person doing it.

### 3. Develop creative language quirks, dialects, memes, and jargon

The linguist [Ferdinand de Saussure](https://en.wikipedia.org/wiki/Ferdinand_de_Saussure) argued there are two kinds of language:

- **La langue** is the formal concept of language. These are words we print in the dictionary, distribute via educational institutions, and reprimand one another for getting it wrong.
- **La parole** is the speech of everyday life. These are the informal, diverse, and creative speech acts we perform in conversations, social gatherings, and text to the group WhatsApp. This is where language evolves.

We have designed a system that automates a standardised way of writing. We have codified _la langue_ at a specific point in time.

What we have left to play with is _la parole_. No language model will be able to keep up with the pace of weird internet lingo and memes. I expect we'll lean into this. Using neologisms, jargon, euphemistic emoji, unusual phrases, ingroup dialects, and memes-of-the-moment will help signal your humanity.

Not unlike teenagers using language to subvert their elders, or oppressed communities developing dialects that allow them to safely communicate amongst themselves.

### 4. Consider institutional verification

This solution feels the least interesting. We're already hearing rumblings of how ‚Äúverification‚Äù by centralised institutions or companies might help us distinguish between meat brains and metal brains.

The idea is something like this: you show up in person to register your online accounts or domains. You then get some kind of special badge or mark online legitimising you as a Real Human.

Google might look something like this:

<ResponsiveImage
  framed
  src="/images/posts/ai-dark-forest/human_google.jpg"
  width="1300px"
  alt="Google search results showing a 'certified human' badge on some items"
/>

The whole thing seems fraught with problems, susceptible to abuse, and ultimately impractical. Would it even be the web if everyone knew you were really a dog?

<ResponsiveImage
  src="/images/posts/ai-dark-forest/Internet_dog.jpeg"
  width="460px"
  alt="The original internet dog meme: 'On the internet, no one knows you're a dog'"
  showalt
/>

The people interested in these ideas also tend to also be blockchainers. Let's not encourage it...

### 5. Show up in meatspace

The final edge we have over language models is that we can prove we're real humans by showing up IRL with our real human bodies. We can arrange to meet Twitter mutuals offline over coffee. We can organise meetups and events and conferences and unconferences and hangouts and pub nights.

For the moment we can also do this confirmation over Zoom, but live video generation is getting good enough that I don't think that defence will last long.

There are of course some who don't have this option; people with physical disabilities. People who live in remote, rural places. People with limited time and caretaking responsibilities for the very young or the very old. They will have a harder time verifying their humanness online. I don't have any grand ideas to help solve this, but I hope we find better solutions than my paltry list.

As the forest grows darker, noisier, and less human, I expect to invest more time in growing relationships and communities offline. Meatspace takes more work but always gives more in return.

{/* ### 4. Be weird */}

{/* We're going to need to get weird. Post-post-post-modern-dadaist level weird. Being [illegible](https://www.ribbonfarm.com/2010/07/26/a-big-little-idea-called-legibility/) is a fairly effective defence mechanism against automated forces. */}

{/* Being so unpredictable and strange that your work only makes sense to a select few is a trade-off. But I bet it's one many online creators will take. */}
